{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convnet Visualiser (VGG19)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from matplotlib.image import imsave\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "model = VGG19(weights='imagenet', include_top=False)\n",
    "print('Model Loaded')\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1 (None, None, None, 64)\n",
      "block1_conv2 (None, None, None, 64)\n",
      "block2_conv1 (None, None, None, 128)\n",
      "block2_conv2 (None, None, None, 128)\n",
      "block3_conv1 (None, None, None, 256)\n",
      "block3_conv2 (None, None, None, 256)\n",
      "block3_conv3 (None, None, None, 256)\n",
      "block3_conv4 (None, None, None, 256)\n",
      "block4_conv1 (None, None, None, 512)\n",
      "block4_conv2 (None, None, None, 512)\n",
      "block4_conv3 (None, None, None, 512)\n",
      "block4_conv4 (None, None, None, 512)\n",
      "block5_conv1 (None, None, None, 512)\n",
      "block5_conv2 (None, None, None, 512)\n",
      "block5_conv3 (None, None, None, 512)\n",
      "block5_conv4 (None, None, None, 512)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    filters, biases = layer.get_weights()\n",
    "    print(layer.name, layer.output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return x / K.sqrt(K.mean(K.square(x))+1e-5)\n",
    "\n",
    "def deprocess_img(x):\n",
    "    x -= x.mean()\n",
    "    x /= (x.std()+1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "layer_name = 'block3_conv4'\n",
    "filter_index = 17\n",
    "\n",
    "input_img = model.input\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "layer_output = layer_dict[layer_name].output\n",
    "loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "grads = K.gradients(loss, input_img)[0]\n",
    "grads = normalize(grads)\n",
    "\n",
    "iterate = K.function([input_img], [loss, grads])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 26.33it/s]\n"
     ]
    }
   ],
   "source": [
    "img_width = 128\n",
    "img_height = 128\n",
    "input_img_data = np.random.random((1, img_width, img_height, 3)) * 20 + 128\n",
    "\n",
    "step = 1.\n",
    "iterations = 20\n",
    "for i in tqdm(range(iterations)):\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    input_img_data += (grads_value*step)\n",
    "\n",
    "    # print('Current loss value:', loss_value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block3_conv4_filter_17.png:Image Saved!!\n"
     ]
    }
   ],
   "source": [
    "img = deprocess_img(input_img_data[0])\n",
    "imsave('%s_filter_%d.png' % (layer_name, filter_index), img)\n",
    "print('%s_filter_%d.png:Image Saved!!' % (layer_name, filter_index))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8d9b8ef5",
   "language": "python",
   "display_name": "PyCharm (DLVS)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}